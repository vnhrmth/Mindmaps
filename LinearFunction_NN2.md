# What Is the Simplest Concept Behind Neural Networks?

- The simplest concept is a **linear function with a threshold**, which is a basic decision-making rule that mimics a neuron’s behavior without any learning or complexity.

## What Is a Linear Function?

- A linear function computes a weighted sum of inputs:
$output = w₁x₁ + w₂x₂ + ... + wₙxₙ$

## What Are the Components?

- **Inputs (x₁, x₂, ..., xₙ)** – raw data
- **Weights (w₁, w₂, ..., wₙ)** – importance of each input
- **Threshold** – decision boundary
- **Output** – binary result (0 or 1)

## What Can This Model Do?

- Make simple binary decisions
- Mimic basic logic gates like AND, OR

## What Can’t It Do?

- Learn from data
- Handle non-linear patterns
- Adapt to new inputs

## Why Is This Important?

- This model is the **foundation** of neural networks. It shows how a simple rule can be used to make decisions, which is later extended with learning, layers, and non-linear functions.
